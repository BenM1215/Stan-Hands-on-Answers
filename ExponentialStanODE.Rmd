---
title: "Exponential Function Ordinary Differential Equation - Stan"
author:
- Ben K. Margetts
- ben.margetts.14@ucl.ac.uk
- UCL Great Ormond Street Institute of Child Health
output:
  html_document:
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
---

This example follows on from the 'Exponential Function - Stan' document.

#Read-in Our Libraries:

Read-in 'rstan', 'knitr', and 'ggplot2'. Configure RStan to run on all available cores of your CPU.
```{r warning=T}
library(rstan)
library(knitr)
library(ggplot2)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

Read-in an R ODE solving package.
```{r}
library(deSolve)
#If not installed, please run the following command: install.packages('deSolve')
```


#Setup Our Notebook

Set options that warn us of any errors, and maintain the same code structure presented here.

```{r setup}
opts_chunk$set(message=T, warning=T, tidy.opts=list(width.cutoff=60),tidy=F)
```


#Simulate Some Data From an Exponential Function

Let's consider the growth of some biological organism. In ideal conditions, where the organism is not limited by space or essential nutrients, its growth could be described using a simple mathematical function.

The function of interest is:

$$y(t) = \alpha e^{\beta t} $$
where $y$ is the amount of the organism, $\alpha$ and $\beta$ are parameters that relate to the initial amount and growth rate of the organism , and $t$ is time. We can simulate some data from this function with ease in R using the following code.

```{r}
# Set up the true parameter values
a <- 0.8
b <- 2
sigma <- .2
     
# Simulate some data
x <- (1:1000)/100
N <- length(x)
obs <- a*exp(b*x)
```


#Ordinary Differential Equation

In this example, we are interested in running this same function, but expressed as an ordinary differential equation (ODE). Consider

$$y = f(t) = \alpha e^{\beta t}$$

Then, remembering the Chain Rule, we can show that $\frac{dy}{dt} = \beta y$ satisfies the equation $y = f(t) = \alpha e^{\beta t}$, where $\frac{dy}{dt}$ gives the change in our variable $y$ over the change in time $t$.

$$\frac{dy}{dt} = \frac{d}{dt}(\alpha e^{\beta t}) = \alpha \frac{de^{\beta t}}{dt}=\alpha \frac{de^u}{du}\frac{du}{dt} = \alpha e^u\beta = \beta(\alpha e^{\beta t}) = \beta y,\\
\frac{dy}{dt} = \beta y$$

Here, $y(0) = \alpha e^{\beta t_0}$. Where $t_0 = 0$, we can say that $\alpha e^{\beta 0} = \alpha e^0 = \alpha \cdot 1 = \alpha$, and therefore, $y(0) = \alpha$.

Let's begin by simulating this ODE system without noise.

```{r}
#Without Noise
t0 <- 0
Y0 <- a*exp(b*t0)
numODEs <- 1
#Create the ODE
Exp <- function(t, state, parameters) {
with(as.list(c(state, parameters)), { 
  dY<- b*Y
  list(dY)
      })
}
parameters <- c(b = 2
                )
state <- c(Y=Y0)
times <- (1:1000)/100
```

We can then run the ODE that we set up above using the following code.

```{r}
#Run the ODE
out <- ode(y = state, times = times, func = Exp, parms = parameters)
```

If we plot the results of the analytical solution of our function against the results from our ODE, we can see that they agree.

```{r}
plot(out[,2],obs)
abline(a=0,b=1, col='red')
```

And again, we can plot the ODE and the analytical solution against time.

```{r}
#Do they equal?
plot(x,obs)
lines(out, col='red')
```

#Introduce Some Noise Into the Dataset

As we did before, we can then add some noise to the results of the ODE, using a log-normal error model.

```{r}
out[,2] <- out[,2]*exp(rnorm(N, 0, sigma))
```

The results of this are plotted below.

```{r}
plot(out[,2],obs)
abline(a=0,b=1, col='red')
```


```{r}
plot(x,obs)
lines(out, col='red')
```

We now need to write our stan code to evaluate these data using its built-in differential equation solvers. The code to do this is more difficult than in the previous example, and so the code has been provided below. Please read it through and try to work out what it is doing.

```{r}
stanProg <- 
'
#We define our ODE here. Ignore x_r and x_i.

functions{
  real[] ode(real time,
                  real[] y,
                  real[] theta,
                  real[] x_r,
                  int[] x_i) {
        real dydt[1];
        dydt[1] = theta[1]* y[1];
        return dydt;
  }
}


#Read-in our data from R.

data { int N;
        int numODEs;      
        real x[N];
        real obs[N];
        real Y0[1];
        real t0;
      }



transformed data{
      real x_r[0];
      int x_i[0];
      }


#Our parameters to estimate go here.

parameters {
       real log_b;
       real<lower=0> sigma;
}


#We evaluate our ODE and transform our parameters back here.

transformed parameters {
      real<lower=0> b;
      real theta[1];
      real ypred[N,numODEs];

      b = exp(log_b);
      theta[1] = b;
      #print(integrate_ode_rk45(ode, Y0, t0, x, theta, x_r, x_i));
      ypred = integrate_ode_rk45(ode, Y0, t0, x, theta, x_r, x_i);
}


#We define the distribution that our data come from here.

model {
       obs ~ lognormal(log(ypred[,1]), sigma);
}'
```


#Fit the Model

We are now ready to fit a model to our data. We will need to provide stan with the code we wrote above and a list containing $N$, $x$, $y$, $t_0$, the number of ODEs, and $y_0$. Try running it for 1000 iterations over 4 chains. 


```{r}
fit <- stan(model_code = stanProg, data=list(N=N, x=x, obs=out[,2], t0=t0, numODEs=numODEs, Y0=array(Y0)), iter=1000, chains=4)
```

#Examining the Output

Assuming all went well with the model fitting, we should now be able to examine the contents of the 'fit' object.

```{r}
print(fit, pars=c("b", "sigma"))
```

If all went well, the printed statment above should confirm that we have recovered the correct parameter estimates, with a narrow confidence interval on our posteriors. $\hat{R} \approx 1$ in this case, suggesting that the model converved as expected.

The 'fit' object contains lots of data on the model fitting process, and it is very simple to extract information from. We can extract our mean parameter estimates from the posteriors and plot them using the following code.

```{r}
b1_mean <- mean(extract(fit)$b)
sigma_mean <- mean(extract(fit)$sigma)
plot(fit, pars=c("b", "sigma"))
```

When debugging a model in Stan, it can be very useful to investigate how the Monte Carlo chains explored the parameter space to converge on the parameter estimates it produced. A traceplot is an easy way to demonstrate this. In this first plot we include the warmup iterations that Stan discards to see how efficiently Stan explored the parameter space.

```{r}
traceplot(fit, inc_warmup=T, pars=c("b", "sigma"))
```

And in this second plot, we focus only on the non-warmup chains. In these plots we can see that the mean value for the 4 chains appears to be the same as that reported for our parameter estimates.

```{r}
traceplot(fit, pars=c("b", "sigma"))
```

We can also make a pairs plot with ease to investigate the relationship between our parameters.

```{r}
pairs(fit, pars=c("b", "sigma"))
```

#Posterior Predictive Checks

Finally, let's confirm that our parameter estimates can reproduce the data. This may seem obvious, given that we know the true value of the parameters, but when modelling data with unknown parameter values, this step is very important.

```{r}
ypred = Y0*exp(b1_mean*x)
plot(x,out[,2])
lines(x,ypred, col='red')
```

We can also plot our predictions on one axis against our data on the other axis. A linear function with a gradient of 1 and a $y$ intercept of 0 plotted over this should then pass straight through our plotted data, if our predictions are accurate.

```{r}
plot(out[,2],ypred, log='xy')
abline(a=0,b=1, col="red")
```



